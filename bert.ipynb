{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm9IMc8BhQN3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification, create_optimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv(\"/content/git_final_vadar.csv\")\n",
        "\n",
        "if \"cleaned_comments\" not in df.columns or \"sentiment_category\" not in df.columns:\n",
        "    raise ValueError(\"Dataset must contain 'cleaned_comments' and 'sentiment_category' columns.\")\n",
        "\n",
        "df = df.dropna(subset=[\"cleaned_comments\", \"sentiment_category\"])\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "X = df[\"cleaned_comments\"].tolist()\n",
        "y = df[\"sentiment_category\"]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train_encoded = tokenizer(X_train, padding=True, truncation=True, max_length=128, return_tensors=\"tf\")\n",
        "X_test_encoded = tokenizer(X_test, padding=True, truncation=True, max_length=128, return_tensors=\"tf\")\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(set(y)))\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 10\n",
        "num_train_steps = (len(X_train) // batch_size) * epochs\n",
        "num_warmup_steps = int(0.1 * num_train_steps)\n",
        "\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps, weight_decay_rate=0.01)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_encoded[\"input_ids\"], X_train_encoded[\"attention_mask\"]],\n",
        "    y_train,\n",
        "    validation_data=([X_test_encoded[\"input_ids\"], X_test_encoded[\"attention_mask\"]], y_test),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate([X_test_encoded[\"input_ids\"], X_test_encoded[\"attention_mask\"]], y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "def plot_training_history(history):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"Train Accuracy\", marker=\"o\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\", marker=\"o\")\n",
        "    axs[0].set_title(\"Model Accuracy\")\n",
        "    axs[0].set_xlabel(\"Epoch\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend()\n",
        "    axs[0].grid()\n",
        "\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"Train Loss\", marker=\"o\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"Validation Loss\", marker=\"o\")\n",
        "    axs[1].set_title(\"Model Loss\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    axs[1].legend()\n",
        "    axs[1].grid()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "sentiment_counts = df[\"sentiment_category\"].value_counts(normalize=True) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(sentiment_counts.index, sentiment_counts.values, color=[\"red\", \"blue\", \"green\"])\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Percentage\")\n",
        "plt.title(\"Sentiment Distribution in Dataset\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n"
      ]
    }
  ]
}